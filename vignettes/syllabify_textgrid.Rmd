---
title: "Syllabifying a Force Aligned TextGrid"
author: "Josef Fruehwald"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

This is a little vignette for how to syllabify the output of a TextGrid from [FAVE-align](https://github.com/JoFrhwld/FAVE), and what you might use it for.

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

This vignette uses the `textgRid` package from Patrick Reidy.

```{r}
install.packages(c("devtools",
                   "tidyverse"),
                 repos = "https://cloud.r-project.org/")
```


```{r eval = T}
library(devtools)
install_github("patrickreidy/textgRid")
```

```{r}
library(textgRid)
library(syllabify)
library(dplyr)
library(purrr)
library(tidyr)
```

I read a brief word list based on the examples from Turton (2017), who was studying /l/ darkening. I then transcribed and force aligned it. We can read it in as a data frame like so:

```{r}
tg_path <- system.file("extdata", "l_reading.TextGrid", package = "syllabify")
tg_df <- as.data.frame(TextGrid(tg_path))
head(tg_df)
```


We can tidy up the TierName column a bit.

```{r}
tg_df <- tg_df %>%
            select(-TierType)%>%
            separate(TierName, into = c("speaker", "tier_type"), sep = " - ")
```


## The Syllabification Workflow - In Prose

I'll briefly describe, in prose, the workflow. If you feel like you learn better from just looking at the code, skip a head to that. If there's something confusing in the code, double check back here.

1. Separate the textgrid into separate phone and word textgrids with properly named columns.
2. `left_join()` the word data frame onto the phone data frame by start time. This will give the first phone in the word all of the word metadata, with NA for the rest. We can then use `fill()` to fully associate each phone with its word metadata.
3. `group_by()` the word metadata, and then `nest()` the phone data. This gives us a data frame with one row per word, and a list column of tibbles which have all of the phone metadata.
4. `map()` `syllabify()` onto the phone column of each phone tibble.
5. `bind_cols()` the resulting syllabification info back onto the original phone tibbles.
6. `unnest()` the phone + syllabification tibbles for the whole shebang.

## The Syllabification Workflow - In Code



Separate into phone and word textgrids, renaming the relevant columns. **Note** It's important to keep the StartTime column as-is for the next joining stage.

```{r}
phon_tier <- tg_df %>% 
                filter(tier_type == "phone")%>%
                rename(phone_index = Index,
                       phone_end = EndTime,
                       phone = Label)%>%
                mutate(phone_start = StartTime)
word_tier <- tg_df %>% filter(tier_type == "word") %>%
                filter(tier_type == "word")%>%
                rename(word_index = Index,
                       word_end = EndTime,
                       word = Label)%>%
                mutate(word_start = StartTime)%>%
                select(-tier_type, -TierNumber)
```

`left_join()` the word data frame onto the phones data frame. You can see all of the rows except for the first phone in each word is NA.

```{r}
phon_tier %>%
  left_join(word_tier)%>%
  head()
```

`fill()` on the word metadata will fill down the word metadata within each word.

```{r}
phon_tier %>%
  left_join(word_tier)%>%
  fill(starts_with("word")) %>%
  head()
```

This stage does some data enrichment, incuding what the next phone is (regardless of word boundary), then for where in the word each phone appears.

```{r}
phon_tier %>%
  left_join(word_tier)%>%
  fill(starts_with("word"))%>%
  mutate(next_phone = lead(phone)) %>%
  group_by(word, word_index, word_start, word_end)%>%
  mutate(phone_n = 1:n(),
         position = case_when(n()==1 ~ "coextensive",
                              phone_n == 1 ~ "initial",
                              phone_n == n() ~ "final",
                              TRUE ~ "internal"))%>%
  head()
```

Next, we nest all of the phone data, and filter out the small pauses (they can't be syllabified).

```{r}
word_nested <- phon_tier %>%
        left_join(word_tier) %>%
        fill(starts_with("word"))%>%
        mutate(next_phone = lead(phone)) %>%
        group_by(word, word_index, word_start, word_end) %>%
        mutate(phone_n = 1:n(),
               position = case_when(n()==1 ~ "coextensive",
                                    phone_n == 1 ~ "initial",
                                    phone_n == n() ~ "final",
                                    TRUE ~ "internal")) %>%
        nest()%>%
        filter(grepl("[A-Z]", word))
```
```{r}
head(word_nested)
```


Now, we syllabify the phone tibbles, and `bind_cols()` the two together. Your first instinct here might be to `join_*()`, but don't.

```{r}
syllabified <- word_nested %>%
    mutate(syll_df = map(data, ~syllabify(.x$phone) %>% select(-phone)),
           joined = map2(data,
                         syll_df,
                         bind_cols))%>%
  unnest(joined)

head(syllabified)
```

## Why?

The original motivation for Turton (2017) was to look at how /l/ was realized in different syllabic contexts. We can filter out just the /l/s now to see where they show up.

```{r}
syllabified %>% 
  filter(phone == "L") %>%
  select(word, phone, position, part, stress, syll, next_phone)
```

-----

Turton, D 2017 Categorical or gradient? An ultrasound investigation of /l/-darkening and vocalization in varieties of English. Laboratory Phonology: Journal of the Association for Laboratory Phonology 8(1): 13, pp. 1â€“31, DOI: https://doi.org/10.5334/labphon.35
